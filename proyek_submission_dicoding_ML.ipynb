{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hanz13/machine-learning-dicoding/blob/main/proyek_submission_dicoding_ML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Perkenalan"
      ],
      "metadata": {
        "id": "2ASC2KgWQQrY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nama: Subhan Ashof\n",
        "\n",
        "Proyek Submission: Membuat klasifikasi gambar batu, gunting , kentas dengan Alogoritma menggunakan Tensorflow.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "CO2XF7cTPzKU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Libraries"
      ],
      "metadata": {
        "id": "crX92kUxQrvr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uZ7Vy3X3PWBl"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "import random\n",
        "import shutil\n",
        "from google.colab import files\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import pandas as pd\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import EarlyStopping,ModelCheckpoint\n",
        "\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, Flatten, Input\n",
        "\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Loading"
      ],
      "metadata": {
        "id": "8K2OQ41-RS5p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#download dataset\n",
        "!wget --no-check-certificate \\\n",
        "https://github.com/dicodingacademy/assets/releases/download/release/rockpaperscissors.zip"
      ],
      "metadata": {
        "id": "8een3-w6RDFm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "folder_to_delete = '/content/dataset/'\n",
        "\n",
        "try:\n",
        "    shutil.rmtree(folder_to_delete)\n",
        "    print(f'Folder {folder_to_delete} dan isinya berhasil dihapus.')\n",
        "except Exception as e:\n",
        "    print(f'Gagal menghapus folder: {str(e)}')"
      ],
      "metadata": {
        "id": "Pw7QPUuwiIU5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#unzip rockpaperscissors.zip dan simpan ke folder dataset\n",
        "!unzip -q rockpaperscissors.zip -d dataset"
      ],
      "metadata": {
        "id": "Tp7VIUPvRM2n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#mengecek isi dir di dalam folder main_path\n",
        "main_path= '/content/dataset/rockpaperscissors'\n",
        "os.listdir(main_path)"
      ],
      "metadata": {
        "id": "dh1D0Sl8RemC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def check_dir(dir: str = None, labels: list = None):\n",
        "    '''\n",
        "    Mengecek jumlah data dalam direktori berdasarkan label.\n",
        "\n",
        "    Parameters:\n",
        "        dir (str): Path ke direktori yang akan diperiksa.\n",
        "        labels (list): List dari label yang akan dicari dalam direktori.\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "\n",
        "    Contoh Penggunaan:\n",
        "    ```python\n",
        "    train_dir = \"/path/to/train_directory\"\n",
        "    test_dir = \"/path/to/test_directory\"\n",
        "\n",
        "    print('Train set: \\n' + '='*50)\n",
        "    check_dir(train_dir, ['PNEUMONIA', 'NORMAL'])\n",
        "\n",
        "    print('\\nTest set: \\n' + '='*50)\n",
        "    check_dir(test_dir, ['PNEUMONIA', 'NORMAL'])\n",
        "    ```\n",
        "\n",
        "    Mencetak jumlah data untuk setiap label yang ditemukan dalam direktori.\n",
        "    '''\n",
        "    for label in labels:\n",
        "        num_data = len(os.listdir(os.path.join(dir, label)))\n",
        "        print(f'Jumlah {label}: {num_data}')"
      ],
      "metadata": {
        "id": "b84I_H1_SQFf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Jumlah gambar pada setiap label: \\n' + '='*50)\n",
        "check_dir(main_path,['rock','paper','scissors'])"
      ],
      "metadata": {
        "id": "J4c22wWkaOch"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_directories(base_dir=None, sub_dir=None, labels=None):\n",
        "    '''\n",
        "    Membuat struktur direktori untuk dataset berdasarkan label.\n",
        "\n",
        "    Parameters:\n",
        "        base_dir (str): Path ke direktori utama.\n",
        "        labels (list): List dari label yang akan digunakan.\n",
        "        sub_dir (list): List dari nama direktori yang akan dibuat.\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "    '''\n",
        "    # Buat direktori 'train' dan/atau 'test'\n",
        "    # Jika direktori tersebut sudah ada maka akan melanjutkan dan tidak akan muncul error.\n",
        "    for sub in sub_dir:\n",
        "        dir_path = os.path.join(base_dir, sub)\n",
        "        os.makedirs(dir_path, exist_ok=True)\n",
        "\n",
        "    # Buat direktori berisi nama labels\n",
        "    for label in labels:\n",
        "        for sub in sub_dir:\n",
        "            label_dir = os.path.join(base_dir, sub, label)\n",
        "            os.makedirs(label_dir, exist_ok=True)\n",
        "\n",
        "    return f'Telah berhasil membuat sub directories :{sub_dir} dan labels: {labels}'"
      ],
      "metadata": {
        "id": "J5er5I2xaLy8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = ['rock', 'paper', 'scissors']\n",
        "list_sub_dir = ['train', 'val']\n",
        "\n",
        "#panggil prosedur create_directories\n",
        "create_directories(main_path,  list_sub_dir, labels)"
      ],
      "metadata": {
        "id": "VYKtQTola-D8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Path ke folder 'train', dan 'test'\n",
        "train_folder = os.path.join(main_path,'train')\n",
        "val_folder = os.path.join(main_path,'val')\n",
        "\n",
        "# path ke folder 'rock', 'paper', 'scissors' (tempat file gambar)\n",
        "rock_folder = os.path.join(main_path,'rock')\n",
        "paper_folder = os.path.join(main_path,'paper')\n",
        "scissors_folder = os.path.join(main_path,'scissors')\n"
      ],
      "metadata": {
        "id": "6_sAqcLUd8Vy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_folder"
      ],
      "metadata": {
        "id": "OysgBl_alsCg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Selanjutnya saya akan membuat sendiri perintah untuk splitting data tanpa menggunakan scikit learn."
      ],
      "metadata": {
        "id": "hMn0d_Jrq_6V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def split_data(source=None, destination=None, label=None,split_percentage=None):\n",
        "    '''\n",
        "    Memindahkan data dan Memisahkan data dari sumber ke destinasi dengan persentase tertentu.\n",
        "\n",
        "    Parameters:\n",
        "        source (str): Path direktori sumber data yang akan dipindahkan.\n",
        "        destination (str): Path ke direktori tujuan.\n",
        "        label (list): Nama label yang akan digunakan.\n",
        "        split_percentage (float): Persentase data yang akan dipindahkan ke destinasi.\n",
        "\n",
        "    Returns:\n",
        "        str: Pesan sukses ketika operasi selesai.\n",
        "\n",
        "    Examples:\n",
        "    ```python\n",
        "    source_folder = 'source'\n",
        "    destination_folder = 'destination'\n",
        "    split_percentage = 0.6\n",
        "    split_data(source_folder, destination_folder, split_percentage)\n",
        "    ```\n",
        "\n",
        "    Fungsi ini memindahkan data dari direktori sumber ke destinasi dengan persentase tertentu,\n",
        "    seperti membagi data menjadi train dan test set.\n",
        "    '''\n",
        "    files = os.listdir(source)\n",
        "    num_files = len(files)\n",
        "    num_train = int(num_files * split_percentage)\n",
        "\n",
        "    # Acak urutan file\n",
        "    random.shuffle(files)\n",
        "\n",
        "    train_files = files[:num_train]\n",
        "    test_files = files[num_train:]\n",
        "\n",
        "    # Pindahkan file ke folder tujuan\n",
        "    for file in train_files:\n",
        "        source_file = os.path.join(source, file)\n",
        "        destination_file = os.path.join(destination[0],label)\n",
        "        shutil.copy(source_file, destination_file)\n",
        "\n",
        "    for file in test_files:\n",
        "        source_file = os.path.join(source, file)\n",
        "        destination_file = os.path.join(destination[1],label)\n",
        "        shutil.copy(source_file, destination_file)\n",
        "\n",
        "    return 'Telah berhasil memasukkan data'\n"
      ],
      "metadata": {
        "id": "e6EQCenaczxP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Persentase data yang akan digunakan sebagai split data\n",
        "train_percentage = 0.6\n",
        "\n",
        "#list folder train dan test\n",
        "destination_folder= [train_folder,val_folder]\n",
        "# Bagi data untuk masing-masing label\n",
        "split_data(rock_folder, destination_folder, 'rock', train_percentage)\n",
        "split_data(paper_folder, destination_folder, 'paper', train_percentage)\n",
        "split_data(scissors_folder, destination_folder,'scissors', train_percentage)"
      ],
      "metadata": {
        "id": "11EFNdXogzYX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Jumlah gambar di train: \\n' + '='*50)\n",
        "check_dir(train_folder,['rock','paper','scissors'])\n",
        "\n",
        "print('Jumlah gambar di test: \\n' + '='*50)\n",
        "check_dir(val_folder,['rock','paper','scissors'])"
      ],
      "metadata": {
        "id": "4t88cCtyrWrh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_random_data(data_dir, label, num_samples=5):\n",
        "    label_dir = os.path.join(data_dir, label)\n",
        "    image_files = os.listdir(label_dir)\n",
        "\n",
        "    num_samples = min(num_samples, len(image_files))\n",
        "    random_images = random.sample(image_files, num_samples)\n",
        "\n",
        "    fig, axes = plt.subplots(1, num_samples, figsize=(10, 2), constrained_layout=True)\n",
        "\n",
        "    # Kurangi jarak antara subplot horizontal dan vertikal\n",
        "    plt.subplots_adjust(wspace=0.2, hspace=0.2)\n",
        "\n",
        "    for j, random_image in enumerate(random_images):\n",
        "        image_path = os.path.join(label_dir, random_image)\n",
        "\n",
        "        img = mpimg.imread(image_path)\n",
        "        image_size = f'Size: {img.shape[1]} x {img.shape[0]}'  # Menampilkan ukuran gambar\n",
        "        title = f'Label: {label}\\n{image_size}'  # Gabungkan label dan ukuran\n",
        "\n",
        "        axes[j].imshow(img)\n",
        "        axes[j].set_title(title)\n",
        "        axes[j].axis('off')\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "label_to_visualize = 'rock'\n",
        "visualize_random_data(main_path, label=label_to_visualize, num_samples=5)"
      ],
      "metadata": {
        "id": "cCbya7RLNSiF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "visualize_random_data(main_path, label='paper', num_samples=5)"
      ],
      "metadata": {
        "id": "DpjlEjK2STga"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "visualize_random_data(main_path, label='scissors', num_samples=5)"
      ],
      "metadata": {
        "id": "WE-NaBf1SWRT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data preprocessing"
      ],
      "metadata": {
        "id": "nGMNrB89ubZR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img_height= 150\n",
        "img_width= 150\n",
        "input_size= (img_height,img_width)"
      ],
      "metadata": {
        "id": "zw78HYNzudM5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "    rescale = 1./255,\n",
        "    rotation_range = 90,\n",
        "    horizontal_flip = True,\n",
        "    vertical_flip = True,\n",
        "    shear_range = 0.2,\n",
        "    fill_mode = 'nearest',\n",
        "    brightness_range=[0.5, 1.5],\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        ")\n",
        "val_datagen = ImageDataGenerator(\n",
        "    rescale = 1./225,\n",
        "    rotation_range = 90,\n",
        "    horizontal_flip = True,\n",
        "    vertical_flip = True,\n",
        "    shear_range = 0.2,\n",
        "    fill_mode = 'nearest',\n",
        "    brightness_range=[0.5, 1.5],\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        ")"
      ],
      "metadata": {
        "id": "cVXV7MG7uj_m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_folder,\n",
        "    target_size=input_size,\n",
        "    batch_size= 32,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "validation_generator = val_datagen.flow_from_directory(\n",
        "    val_folder,\n",
        "    target_size = input_size,\n",
        "    batch_size = 32,\n",
        "    class_mode = 'categorical',\n",
        "    shuffle=False\n",
        ")"
      ],
      "metadata": {
        "id": "C9lAyzYiyFry"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_indices = train_generator.class_indices\n",
        "print(class_indices)"
      ],
      "metadata": {
        "id": "jy0k_H9PgiwN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def display_augmented_images(data_generator, num_samples_to_display=10):\n",
        "    num_rows= 2\n",
        "    num_cols = int(num_samples_to_display/num_rows)\n",
        "\n",
        "    fig, axes = plt.subplots(num_rows, num_cols, figsize=(12, 6))\n",
        "    for i in range(num_rows):\n",
        "        for j in range(num_cols):\n",
        "            batch = data_generator.next()\n",
        "            image = batch[0][0]  # Ambil gambar pertama dari batch\n",
        "            label = batch[1][0]  # Ambil label pertama dari batch\n",
        "\n",
        "            # Konversi label dalam format one-hot encoding ke kelas asli\n",
        "            class_index = label.argmax()\n",
        "\n",
        "            # Menampilkan gambar\n",
        "            axes[i, j].imshow(image)\n",
        "            axes[i, j].set_title(f\"Class: {class_index}\")\n",
        "            axes[i, j].axis('off')\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "display_augmented_images(train_generator, num_samples_to_display=10)\n"
      ],
      "metadata": {
        "id": "oWslWLEXTiYm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sequatial Model"
      ],
      "metadata": {
        "id": "DVq_p0XPyxg9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape=(img_height,img_width,3)\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Conv2D(32, (3,3), activation = 'relu', input_shape= input_shape),\n",
        "  tf.keras.layers.MaxPooling2D(2,2),\n",
        "  tf.keras.layers.Conv2D(64,(3,3), activation= 'relu'),\n",
        "  tf.keras.layers.MaxPooling2D(2,2),\n",
        "  tf.keras.layers.Conv2D(128,(3,3), activation= 'relu'),\n",
        "  tf.keras.layers.MaxPooling2D(2,2),\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dropout(0.4),\n",
        "  tf.keras.layers.Dense(128, activation= 'relu'),\n",
        "  tf.keras.layers.Dense(128, activation= 'relu'),\n",
        "  tf.keras.layers.Dense(3, activation= 'softmax')\n",
        "])\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "17smzLp9vH9H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = tf.keras.optimizers.experimental.Nadam()\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "2ja8DmAd6um6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks = [\n",
        "    EarlyStopping(monitor='val_loss', patience= 3, min_delta=0.1),\n",
        "    ModelCheckpoint('model_best2.h5', monitor='val_loss', save_best_only=True)\n",
        "]"
      ],
      "metadata": {
        "id": "g8dAmQxQzowF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pada code dibawah ini validation_Steps dan steps_per_epoch secara otomatis akan sesuai dengan jumlah batch dan images. Rumusnya `number_images/batch_size`"
      ],
      "metadata": {
        "id": "k0soDyfDBt7Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    train_generator,\n",
        "    validation_data = validation_generator,\n",
        "    # validation_steps = 14, #  number_images/batch_size = 876/64\n",
        "    # steps_per_epoch = 21, #  number_images/batch_size= 1312/64\n",
        "    epochs = 100,\n",
        "    callbacks= callbacks\n",
        ")"
      ],
      "metadata": {
        "id": "d2nMdF2mzdvW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluasi Model"
      ],
      "metadata": {
        "id": "7Ea_dbuxwrZ6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "# Membuat dataframe\n",
        "data = {\n",
        "    'Epoch': range(1, len(acc) + 1),\n",
        "    'Accuracy': acc,\n",
        "    'Validation Accuracy': val_acc,\n",
        "    'Loss': loss,\n",
        "    'Validation Loss': val_loss\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Menampilkan dataframe\n",
        "display(df)"
      ],
      "metadata": {
        "id": "u8TerFzIdKdf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs_range= range(1, len(acc) + 1)\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "wTHpmAt-H_P1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load model_best2.h5\n",
        "# Ganti dengan path ke file model_best2.h5\n",
        "model_path = '/content/model_best2.h5'\n",
        "\n",
        "# Memuat model\n",
        "loaded_model = load_model(model_path)"
      ],
      "metadata": {
        "id": "HmM7aXhfcolh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#evaluasi dengan model_best2.h5\n",
        "test_results_best = loaded_model.evaluate(validation_generator, verbose=0)\n",
        "print(f'Test Loss     : {test_results_best[0]:.4f}')\n",
        "print(f'Test Accuracy : {test_results_best[1]:.4f}')"
      ],
      "metadata": {
        "id": "MXsmk2YCcZE0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#evaluasi model bukan dari model_best2.h5\n",
        "test_results = model.evaluate(validation_generator, verbose=0)\n",
        "print(f'Test Loss     : {test_results[0]:.4f}')\n",
        "print(f'Test Accuracy : {test_results[1]:.4f}')"
      ],
      "metadata": {
        "id": "nv7PD871eNwj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dapat kita lihat bahwa dengan menggunakan modelcheckpoint `model_best2.h5` , kita dapat hasil yang lebih bagus, karena sebelumnya kita telah atur ke `save_best_only=True`"
      ],
      "metadata": {
        "id": "m5Y1mHzZejvR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class_indices = train_generator.class_indices\n",
        "class_indices.keys()"
      ],
      "metadata": {
        "id": "8mDSATaTg7jm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fungsi untuk mengunggah dan memprediksi gambar\n",
        "def upload_and_predict_image(model):\n",
        "    # Upload gambar\n",
        "    uploaded = files.upload()\n",
        "\n",
        "    # Mendapatkan label hasil prediksi\n",
        "    labels = ['paper', 'rock', 'scissors']\n",
        "\n",
        "    for image_path in uploaded.keys():\n",
        "        # Augmentasi gambar dengan random_invert\n",
        "        img = image.load_img(image_path, target_size=(150, 150))\n",
        "        img = image.img_to_array(img)\n",
        "        img = img / 255.0  # Preprocessing gambar (normalisasi)\n",
        "\n",
        "\n",
        "        img = np.expand_dims(img, axis=0)\n",
        "\n",
        "        # Melakukan prediksi\n",
        "        prediction = loaded_model.predict(img)\n",
        "        print(prediction)\n",
        "\n",
        "        # Mendapatkan hasil prediksi\n",
        "        predicted_class = labels[np.argmax(prediction)]\n",
        "        predicted_probability = np.max(prediction)\n",
        "\n",
        "        # Menampilkan gambar\n",
        "        plt.figure()\n",
        "        img = mpimg.imread(image_path)\n",
        "        plt.imshow(img)\n",
        "        plt.title(f'Hasil prediksi: {predicted_class}\\nProbabilitas: {predicted_probability:.2f}')\n",
        "        plt.axis('off')\n",
        "        plt.show()\n",
        "\n",
        "# Contoh penggunaan\n",
        "# Gantilah loaded_model dengan model yang sesuai dengan tugas Anda\n",
        "upload_and_predict_image(loaded_model)\n"
      ],
      "metadata": {
        "id": "qZTWJmzUz53c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 38
        },
        "outputId": "21d126da-ab0c-4738-d47c-2991a72b8e8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-a2385fd7-911c-4676-a46c-45a4cbaafbb9\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-a2385fd7-911c-4676-a46c-45a4cbaafbb9\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}