{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hanz13/machine-learning-dicoding/blob/main/ml_subhan_dicoding.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TFb2yPf1SV7g"
      },
      "source": [
        "Nama : Subhan Ashof\n",
        "\n",
        "**Project Akhir Submission Dicoding**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SN2Z18anVcvG"
      },
      "source": [
        "## Import library dan fetch dataset dari server\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VbrfwXKdVyH_"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.model_selection import train_test_split\n",
        "import zipfile,os,shutil"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5H5C81DyVbTt",
        "outputId": "c7898dcb-6c00-4364-caca-e25e3b3e1887",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!wget --no-check-certificate \\\n",
        "  https://dicodingacademy.blob.core.windows.net/picodiploma/ml_pemula_academy/rockpaperscissors.zip \\\n",
        "  -O /tmp/rockpaperscissors.zip"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-12-23 07:18:23--  https://dicodingacademy.blob.core.windows.net/picodiploma/ml_pemula_academy/rockpaperscissors.zip\n",
            "Resolving dicodingacademy.blob.core.windows.net (dicodingacademy.blob.core.windows.net)... 20.60.139.65\n",
            "Connecting to dicodingacademy.blob.core.windows.net (dicodingacademy.blob.core.windows.net)|20.60.139.65|:443... connected.\n",
            "HTTP request sent, awaiting response... 404 The specified resource does not exist.\n",
            "2023-12-23 07:18:24 ERROR 404: The specified resource does not exist..\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DUX-_OecQT5S",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "outputId": "eff7db13-1eda-4b59-97a0-815f2c15d7f7"
      },
      "source": [
        "#ekstrak dataset\n",
        "local_zip = '/tmp/rockpaperscissors.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp')\n",
        "zip_ref.close()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "BadZipFile",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mBadZipFile\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-fe8c6b71dbaa>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#ekstrak dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mlocal_zip\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/tmp/rockpaperscissors.zip'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mzip_ref\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocal_zip\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mzip_ref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/tmp'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mzip_ref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/zipfile.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps)\u001b[0m\n\u001b[1;32m   1267\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1268\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1269\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_RealGetContents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1270\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'w'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'x'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1271\u001b[0m                 \u001b[0;31m# set the modified flag so central directory gets written\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/zipfile.py\u001b[0m in \u001b[0;36m_RealGetContents\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1334\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mBadZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"File is not a zip file\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1335\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mendrec\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1336\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mBadZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"File is not a zip file\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1337\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1338\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendrec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mBadZipFile\u001b[0m: File is not a zip file"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWm10e9ol0sE"
      },
      "source": [
        "# Penggunaan Callback mencegah overfitting dan menghentikan training setelah akurasi terpenuhi\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs.get('accuracy') > 0.97):\n",
        "      print(\"\\nAkurasi di atas 97%, hentikan training!\")\n",
        "      self.model.stop_training = True\n",
        "\n",
        "callbacks = myCallback()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qp34911gQ-d7"
      },
      "source": [
        "## split dataset , membuat direktori\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yxnpmQEzVGhX"
      },
      "source": [
        "base_dir = '/tmp/rockpaperscissors'\n",
        "train_dir = os.path.join(base_dir,'train')\n",
        "validation_dir = os.path.join(base_dir, 'val')\n",
        "roc_dir = os.path.join(base_dir,'rock')\n",
        "pap_dir = os.path.join(base_dir, 'paper')\n",
        "sci_dir = os.path.join(base_dir, 'scissors')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0nx-EwantZiX"
      },
      "source": [
        "os.mkdir(train_dir)\n",
        "os.mkdir(validation_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XoNMavVhtFNf"
      },
      "source": [
        "train_roc = os.path.join(train_dir, 'rock')\n",
        "train_pap = os.path.join(train_dir, 'paper')\n",
        "train_sci = os.path.join(train_dir, 'scissors')\n",
        "val_roc = os.path.join(validation_dir, 'rock')\n",
        "val_pap = os.path.join(validation_dir, 'paper')\n",
        "val_sci = os.path.join(validation_dir, 'scissors')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BVCfRs-uXIAe"
      },
      "source": [
        "os.mkdir(train_roc)\n",
        "os.mkdir(train_pap)\n",
        "os.mkdir(train_sci)\n",
        "os.mkdir(val_roc)\n",
        "os.mkdir(val_pap)\n",
        "os.mkdir(val_sci)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yp-n0pCNcNDb"
      },
      "source": [
        "## Train & test Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "spiFYMNFcRfE"
      },
      "source": [
        "# memecah setiap direktori menjadi data train dan data validasi(validation 40% of dataset)\n",
        "train_roc_dir, val_roc_dir = train_test_split(os.listdir(roc_dir), test_size = 0.40)\n",
        "train_pap_dir, val_pap_dir = train_test_split(os.listdir(pap_dir), test_size = 0.40)\n",
        "train_sci_dir, val_sci_dir = train_test_split(os.listdir(sci_dir), test_size = 0.40)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R87h3wSFeEgY"
      },
      "source": [
        "for file in train_roc_dir:\n",
        "  shutil.copy(os.path.join(roc_dir, file), os.path.join(train_roc, file))\n",
        "for file in train_pap_dir:\n",
        "  shutil.copy(os.path.join(pap_dir,file), os.path.join(train_pap,file))\n",
        "for file in train_sci_dir:\n",
        "  shutil.copy(os.path.join(sci_dir,file), os.path.join(train_sci,file))\n",
        "for file in val_roc_dir:\n",
        "  shutil.copy(os.path.join(roc_dir, file), os.path.join(val_roc,file))\n",
        "for file in val_pap_dir:\n",
        "  shutil.copy(os.path.join(pap_dir,file), os.path.join(val_pap,file))\n",
        "for file in val_sci_dir:\n",
        "  shutil.copy(os.path.join(sci_dir,file), os.path.join(val_sci,file))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JFwYg436eqFY"
      },
      "source": [
        "## augmentation and generate image data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1FUacYtpeyeW"
      },
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "    rescale = 1./255,\n",
        "    rotation_range = 20,\n",
        "    horizontal_flip = True,\n",
        "    shear_range = 0.2,\n",
        "    fill_mode = 'nearest',\n",
        ")\n",
        "test_datagen = ImageDataGenerator(\n",
        "    rescale = 1./225,\n",
        "    rotation_range = 20,\n",
        "    horizontal_flip = True,\n",
        "    vertical_flip = True,\n",
        "    shear_range = 0.2,\n",
        "    fill_mode = 'nearest'\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EuhfeNozf8su"
      },
      "source": [
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(150,150),\n",
        "    batch_size= 32,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "    validation_dir,\n",
        "    target_size = (150,150),\n",
        "    batch_size = 32,\n",
        "    class_mode = 'categorical'\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h5V4DrXBhnVN"
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Conv2D(32, (3,3), activation = 'relu', input_shape= (150,150,3)),\n",
        "  tf.keras.layers.MaxPooling2D(2,2),\n",
        "  tf.keras.layers.Conv2D(64,(3,3), activation= 'relu'),\n",
        "  tf.keras.layers.MaxPooling2D(2,2),\n",
        "  tf.keras.layers.Conv2D(128,(3,3), activation= 'relu'),\n",
        "  tf.keras.layers.MaxPooling2D(2,2),\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dropout(0.5),\n",
        "  tf.keras.layers.Dense(512, activation= 'relu'),\n",
        "  tf.keras.layers.Dense(3, activation= 'softmax')\n",
        "])\n",
        "\n",
        "model.summary()\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=tf.optimizers.Adam(),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0cfjaGUIh2ah"
      },
      "source": [
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch = 41, # 1312 images = batch_size * steps\n",
        "    epochs = 20,\n",
        "    validation_data = validation_generator,\n",
        "    validation_steps = 27, # 876 images = batch_size * steps\n",
        "    verbose =2,\n",
        "      callbacks=[callbacks]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pvUTymHHgfmE"
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "#loss train & validation\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Loss Plot')\n",
        "plt.ylabel('Value')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(loc=\"upper right\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0eYD9ATQnggA"
      },
      "source": [
        "#accuracy train & validation\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Accuracy Plot')\n",
        "plt.ylabel('Value')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zanp_kIXn9kO"
      },
      "source": [
        "#main driver\n",
        "import numpy as np\n",
        "from google.colab import files\n",
        "from keras.preprocessing import image\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "%matplotlib inline\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "\n",
        "  path = fn\n",
        "  img = image.load_img(path, target_size =(150,150))\n",
        "  imgplot = plt.imshow(img)\n",
        "  x = image.img_to_array(img)\n",
        "  x = np.expand_dims(x, axis=0)\n",
        "\n",
        "  images = np.vstack([x])\n",
        "  classes = model.predict(images, batch_size=10)\n",
        "\n",
        "  print(fn)\n",
        "  if classes[0,0]!=0:\n",
        "    print('paper')\n",
        "  elif classes[0,1]!=0:\n",
        "    print('rock')\n",
        "  else:\n",
        "    print('scissors')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}